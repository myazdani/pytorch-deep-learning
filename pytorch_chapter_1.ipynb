{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-chapter-1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myazdani/pytorch-deep-learning/blob/master/pytorch_chapter_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5AXZazcrN_k",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 1\n",
        "\n",
        "# What is PyTorch?\n",
        "\n",
        "PyTorch is a Python library for building computational graphs. Even though you might see it used in a lot of deep learning or machine learning applications, it is much more general. But what is a computational graph? \n",
        "\n",
        "A computational graph is a graph-based framework for describing algebraic expressions such as y = 2x or y = mx + b along with their derivatives. Such computational graphs are usually shown like below:\n",
        "\n",
        "![alt text](https://pbs.twimg.com/media/D4II6qjU0AAYbgx.jpg:small)\n",
        "\n",
        "Above we see a graph that is a collection of nodes and directed edges. In a computational graph the edges represent functions applied on data: in our simple example the multiplication of two values. The nodes store data values, in this case the constant “2”, and the variables “x” and “y”. When we use the computation graph to compute y = 2x, this is referred to as the forward computation or the forward pass. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Often in scientific computing and machine learning, we are not just interested in the forward computation, but also want to know how this function is changing. In other words,  we want to compute the derivative of this function. Because of the importance of derivatives, the nodes in the computational graph are also endowed with the derivatives of the incoming edges that express a computation. This framework allows us to compute derivatives efficiently with what is referred to as backward computation or the backward pass. We will cover these ideas much further later in the chapter. \n",
        "\n",
        "\n",
        "At first the computational graph framework may seem like an excessive way of computing algebraic expression. However, the ability for forward computation (just algebraic expressions) along with backward computation (their respective derivatives) provides an incredible efficient and unified framework for numerous scientific applications including machine learning. The computational graph really shines at taking derivatives because complicated algebraic expression reduce to a series of backward computations, freeing us humans from the need to analytically derive derivatives. \n",
        "\n",
        "PyTorch provides a computational graph framework that allows us to perform forward and backward computation at ease. PyTorch comes equipped with several useful data structures and modules that makes defining graphs easy. In particular, in this book we will be covering at great length:\n",
        "\n",
        "- torch.Tensors: the primary data structure in PyTorch, Tensors are multi-dimensional arrays equipped with numerous linear algebraic methods. If you are a NumPy user, learning PyTorch Tensor comes at ease since the syntax is similar. In addition to sharing many similarities with NumPy arrays, PyTorch Tensors can also be offloaded on GPU with CUDA support to take advantage of accelerated matrix multiplications. \n",
        "- torch.autograd: The autograd module keeps track of the forward computations in the computation graph to then allow us to perform automatic differentiation in the backward pass. \n",
        "- torch.optim: A collection of gradient-based optimization solvers, such as Stochastic Gradient Descent and Adam. \n",
        "- torch.nn: While the operations in torch.Tensors will allow us to define any computational graph, certain computations in deep learning are so common that torch.nn will provide a high level API for them. Typically for deep learning applications, torch.nn is used to create sophisticated high level neural network architectures.\n",
        "\n",
        "If you do not understand what a lot of the terms above means at this point, do not fret. We just want to give a high level overview of what PyTorch is about and will be spending the rest of the book to get into the details here. \n",
        "\n",
        "The latest news and information on PyTorch can be found on https://pytorch.org/ and the package itself is on GitHub: https://github.com/pytorch/pytorch. PyTorch also has a thriving online community with online forums https://discuss.pytorch.org/ and on popular social media platforms such as Facebook and Twitter. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywj9__u9rg8S",
        "colab_type": "text"
      },
      "source": [
        "# Downloading and installing PyTorch\n",
        "\n",
        "PyTorch can be downloaded and installed in your system with several popular methods. Like most popular Python libraries, PyTorch can be downloaded with either the pip or conda package managers. To install PyTorch from the source, follow the latest instructions from GitHub: https://github.com/pytorch/pytorch#from-source\n",
        "\n",
        "Setting up the right computing environment can be tricky and take some work. To ensure uniformity (and as recommended by the PyTorch distributors),  we suggest using the conda package manager and installing the Anaconda environment (https://www.anaconda.com/distribution/ ). In addition to providing the excellent package manager conda, the Anaconda environment also provides many essential scientific computing libraries that we will use such as NumPy, SciPy, and MatplotLib, and Intel’s highly efficient Math Kernel Library (MKL) that includes BLAS and other fast optimized Linear Algebra routines. If you are installing PyTorch make sure these libraries are installed (and if you have an NVIDIA GPU you will need to install CUDA support with the libraries CUDA and cuDNN). See the latest details on package version numbers here: https://github.com/pytorch/pytorch#from-source\n",
        "\n",
        "The PyTorch.org website nicely summarizes the different ways of installing PyTorch, with which version of OS, package manager, Python and CUDA version. For example, in the figure below from PyTorch.org shows how to install PyTorch 1.0 on Linux using the Conda package manager:\n",
        "\n",
        "![alt text](https://pbs.twimg.com/media/D4INajSVUAAsGXB.jpg:large)\n",
        "\n",
        "\n",
        "`conda install pytorch torchvision cudatoolkit=9.0 -c pytorch`\n",
        "\n",
        "In addition to installing PyTorch, the above command also installs the torchvision (specialized PyTorch library for image processing and computer vision applications) and the CUDA Toolkit libraries. \n",
        "\n",
        "Once you have downloaded and successfully installed PyTorch, you should be able import to from the python prompt:\n",
        "\n",
        "`>> import torch`\n",
        "\n",
        "If you have gotten to this step without any errors, congratulations! You now have PyTorch on your machine and ready to use one of the most powerful machine learning frameworks of today!\n",
        "\n",
        "## Additional PyTorch libraries\n",
        "\n",
        "In addition to PyTorch, libraries like torchvision augment the components of PyTorch with additional functions for tensor manipulations of specialized data structures such as images, text, and audio. torchvision, for example, provides interfaces for commonly used datasets such as MNIST and CIFAR and common ways of transforming images (such cropping and rotating). See https://pytorch.org/docs/stable/torchvision/ for more details on the official documentation.\n",
        "\n",
        "Similarly, the torchaudio package is the audio analog of torchvision. torchaudio also has common datasets and audio transformations included in the package. See https://pytorch.org/audio/\n",
        "for more details on the official documentation. Similarly, the torchtext library provides similar functionalities for dealing with text data types and the official documentation can be found here: https://torchtext.readthedocs.io/en/latest/index.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huttOokAXoEo",
        "colab_type": "text"
      },
      "source": [
        "# Working with Tensors in PyTorch\n",
        "\n",
        "\n",
        "While a tensor is a special type of mathematical object with its own tensor calculus, for practical machine learning applications we can think of a tensor simply as a numeric multidimensional array. PyTorch tensors share many similarities with NumPy arrays and follow similar functionality. In fact, you can think of PyTorch tensors as NumPy arrays but with extra computational super powers. The biggest advantages of using PyTorch over NumPy arrays are the ability to track gradients for backward computation (ie, the backward pass or backpropagation for computing automatic differentiation to be covered later) and the ability to offload computations on the GPU. In fact, the success of modern deep learning has relied on the ease of computing gradients and doing it quickly thanks to GPU acceleration. \n",
        "\n",
        "\n",
        "\n",
        "Understanding tensors is at the core of using PyTorch and building deep learning applications and we will cover it here at some length. Here are examples of three tensors:\n",
        "\n",
        "[0.1], [2.1, -1.1, 0, 4], 2d \n",
        "\n",
        "The first example that has just one number is usually called a “0 dimensional tensor”, the middle example is just a list of numbers that we call a “1 dimensional” tensor and the last example is a list of lists or a “2 dimensional” tensor. We can keep adding these lists together to get even higher dimensional tensors and it is very common in deep learning applications to see tensor dimensions go to 3, 4, or even much, much more.\n",
        "\n",
        "In other words, tesnors in PyTorch are a special type of data structure for organizing a collection of numbers. Mathematically though, they are much deeper than just a “collection of numbers.” We will later describe some mathematical, but intuitive, interpretations that will help immensely in appreciating the importance of tensors. \n",
        "\n",
        "\n",
        "## Creating tensors in PyTorch\n",
        "\n",
        "Let's create some tensors in PyTorch and manipulate them to get a feel. We will import the `torch` library and create a simple tensor of three elements and store it in the variable `x`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSDd10rpgWTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNaCbyomgbir",
        "colab_type": "code",
        "outputId": "77a4e32b-71da-4356-8c43-56511cdadb2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([-1.3, 9.1, 3.3])\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.3000,  9.1000,  3.3000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCxA52iLPAYY",
        "colab_type": "text"
      },
      "source": [
        "All we had to do to create a PyTorch tensor was create a regular Python list, followed by using the `torch.tensor` function. As expected, we could have just easily done something like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my5Kyx9APC5D",
        "colab_type": "code",
        "outputId": "15101aae-859e-45e0-e28e-ebf055c422aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_list = [-1.3, 9.1, 3.3]\n",
        "x_tensor = torch.tensor(x_list)\n",
        "print(x_tensor)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.3000,  9.1000,  3.3000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyKQkHQpPfya",
        "colab_type": "text"
      },
      "source": [
        "The above cell makes our steps very clear: we first make a python list and store it in the variable `x_list`. We then use the function `torch.tensor` to store the Python list as a PyTorch tensor in the variable `x_tensor`.\n",
        "\n",
        "Like all variables in Python, `x`, `x_list`, and `x_tensor` are all objects. Specifically we can see that `x` is the `tensor.Tensor` object in PyTorch as expected:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAbH7QTsQEp1",
        "colab_type": "code",
        "outputId": "e277a825-ae51-4afd-c72c-7c4a8b5d4cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCR123GaQD_r",
        "colab_type": "text"
      },
      "source": [
        "And we can similarly inspect the object types for the variables `x_list` and `x_tensor` we have created so far. \n",
        "\n",
        "Often when we are dealing with tensors, we are referring to them as variable names such as `x`. In our toy example we know the dimension is 1 and that there are 3 total elements because we dedfined the tensor and we printed it. \n",
        "\n",
        "While we could try to print the variable like we have done here to know what its dimension and number of elements is, that would take far too long for us to individually count. Moreover, in modern machine learning applications, the total number of elements in the tensor can be anywhere from hundreds to many millions! Surely there is a better way of knowing the number of elements than just counting!\n",
        "\n",
        "Of course, just like NumPy Arrays, PyTorch torch tensors are equipped with numerous methods that allow us to perform many common operations. \n",
        "\n",
        "To know the dimension of the array, we can simply use the `.dim()` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhfYZYbPQf8D",
        "colab_type": "code",
        "outputId": "6ba23cae-7e68-4aaf-c267-ee7081bf1e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.dim()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLIQXMqobvC2",
        "colab_type": "text"
      },
      "source": [
        "In our example with the tensor `x` we see that dimension of the tensor is 1 as we would expect. To know the number of elements in our tensor, we can use the `.size()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akDnUTbaQj3N",
        "colab_type": "code",
        "outputId": "ef617937-dd94-4652-e145-11ebc8630718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.size()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnGpvE7gcKv1",
        "colab_type": "text"
      },
      "source": [
        "Again, since we have a list of 3 items we see that the size of the tensor is what we expect. Note that the `size` method returns a PyTorch object `torch.Size`.  If you want just a pure numeric integer that gives us the number of elements,  you can use the `numel()` method on a `torch.Size` object as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20NabyYncvHi",
        "colab_type": "code",
        "outputId": "87656eda-388b-440f-fc68-59400124bddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.size().numel()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnEluqLhdghF",
        "colab_type": "text"
      },
      "source": [
        "Such decisions depend on the program you are trying to write and the style of programming you are trying to use along with all the variets of syntatctic sugar. \n",
        "\n",
        "\n",
        "Having covered some of the basics of what tensors look like, lets create a slightly more sophisticted tensor. Here we will make a 2 dimensional tensor with 2 rows and 3 columns with random values (from normal random generator):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK5PTOi5dfte",
        "colab_type": "code",
        "outputId": "b57b00e6-74a6-446a-b1e6-bf2b05fe9142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "z = torch.randn(2,3)\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7686, -1.0158, -3.0055],\n",
            "        [-0.7388,  0.9558, -0.6715]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fold6eR9egSe",
        "colab_type": "text"
      },
      "source": [
        "Again, each element in `z` is dawn from a normal distribution so the values you print on your computer will be different on your machine. We can again use the `dim()` and `size()` methods to get verify the shape of this tensor without having to print it and individually count the elements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KysXeHdfdLIq",
        "colab_type": "code",
        "outputId": "ac384b6c-b90a-463a-9a76-6251d0434ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z.dim()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp7tHOsLed0t",
        "colab_type": "code",
        "outputId": "4b4fcde2-3f66-42bc-9872-ac7a7d7ee198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WLf4zkpffyH",
        "colab_type": "text"
      },
      "source": [
        "The `torch.randn()` method doesn't just limit us to create 2 dimensional tensors, however. We can artibitrarily stack a high dimensional tensor by continuing to specify how many elemenrts should be in each dimension. For example, below we create a 4 dimensional tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5fYnmeUe3yL",
        "colab_type": "code",
        "outputId": "c36bc499-ab09-4af4-9edd-864f12be33af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "high_dim_tensor = torch.randn(2,3,4,2)\n",
        "high_dim_tensor.size()\n",
        "high_dim_tensor.dim()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHOpewarf6lf",
        "colab_type": "text"
      },
      "source": [
        "This 4 dimensional tensor has 2 elements in its first dimesnion, 3 elements in the second, 4 in the third dimension, and 2 elements in the fourth and last dimension. \n",
        "\n",
        "Just as in Numpy Arrays, we can use \"indexing\" to access specific parts of a tensor. Let's say we only wanted to print the first row of `z`. We can use the same bracket syntax (called indexing slicing) used in Numpy Arrays on PyTorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPvRoA1DjTxa",
        "colab_type": "code",
        "outputId": "793ae823-cccb-412f-9d95-64a46cd7557c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(z[0,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.7686, -1.0158, -3.0055])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om11VnPHjXwi",
        "colab_type": "text"
      },
      "source": [
        "The `:` indicates that we want every single element in the dimension (in this case the second dimension, also known as the column) to be displayed.  Similarly, if we want to print the last column, we could either use the index 2 (remember indexing in Python starts with 0) or simply -1 (element from the end):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loHatZKBjWhE",
        "colab_type": "code",
        "outputId": "103d5b92-6055-429f-bcdc-07d6a7074701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z[:,-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.0055, -0.6715])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDePhCiAj2Sl",
        "colab_type": "text"
      },
      "source": [
        "If we want to add the first row of `z` with `x`, we can just simply add the two tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hoi0y6mVjxQc",
        "colab_type": "code",
        "outputId": "ebb82e27-96c0-4fed-a7a6-b5a30ef76d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z[0,:] + x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5314,  8.0842,  0.2945])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNXqS1Mvj_fy",
        "colab_type": "text"
      },
      "source": [
        "Similarly, if we want to add the second row of `z` to `x` we can just do:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcYhUoC4j-7v",
        "colab_type": "code",
        "outputId": "6e39d836-575e-4c70-c5fa-29c3b74b0b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z[1,:] + x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.0388, 10.0558,  2.6285])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDVVtL3TkI2x",
        "colab_type": "text"
      },
      "source": [
        "But what happens if we do `z + x`? Readers with a Linear Algebra background may object that such an operation doesn't make sense since the shapes of the two tensors do not line up. While mathematically that is true, in PyTorch it is perfectly legal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny22eyzajVPc",
        "colab_type": "code",
        "outputId": "156506bd-3443-4a7e-abe0-982fac5e9e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "z + x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5314,  8.0842,  0.2945],\n",
              "        [-2.0388, 10.0558,  2.6285]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNzYdi4DlzE7",
        "colab_type": "text"
      },
      "source": [
        "What is going on here?! As you can see, PyTorch has done something very clever. Behind the scenes, PyTorch  notices that there is a dimension mismatch between `x` and `z` but that the number of elements in the single dimension of `x` matches with the second dimension in `z`. Let's review again the shapes of the two tensors with the `size()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3-Qyw2yfvRD",
        "colab_type": "code",
        "outputId": "9b98aaaf-7d2f-449d-e096-2ab24b7f839b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"The shape of z is\", z.size())\n",
        "print(\"The shape of x is\", x.size())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of z is torch.Size([2, 3])\n",
            "The shape of x is torch.Size([3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wEKMACCmWjt",
        "colab_type": "text"
      },
      "source": [
        "Since the single dimension in `x` has 3 elements and the second dimension in `z` has 3 elements, PyTorch *broadcasts* `x` into 2 dimensional arrays that look something like this:\n",
        "\n",
        "\n",
        "\n",
        "Once this is done then addition follows what we expect. This technique is referred to as *broadcasting* and is a common operation in NumPy and PyTorch.\n",
        "While you can certainly create a for loop that goes through each row in `z` and adds to `x`, broadcasting is often much faster. In fact, broadcasting is usually preferred when you consider the following example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQYI41cIiTCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "big_matrix = torch.randn(1000,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLo9qjTIk8OW",
        "colab_type": "code",
        "outputId": "ad69c99c-c96c-4ddf-be07-c231fe779943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "\n",
        "for i in range(1000):\n",
        "    _ = big_matrix[i,:] + x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 5.59 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXtfGF6foEi2",
        "colab_type": "text"
      },
      "source": [
        "We are storing the values into the dummy variable `_` since we do not care about actual values here. We just want to know how fast it is to go through each row in a big tensor to add to another tensor.\n",
        "\n",
        "Now lets do the same thing using broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbXaxd0_iXkh",
        "colab_type": "code",
        "outputId": "e6dac725-6301-4f05-e276-c2bd0f006f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%timeit\n",
        "\n",
        "_ = big_matrix + x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 8.53 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 3: 21.5 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mef1maGxoRFb",
        "colab_type": "text"
      },
      "source": [
        "Whoa! Now this is much faster!!!! For this reason you will often see people use broadcasting to great extend. \n",
        "\n",
        "We can see see that broadcasting can work with any aribitraty dimension tensors as long as the number of elements match up:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF4hf_pfiYlp",
        "colab_type": "code",
        "outputId": "3f622cf9-00cb-4fff-f924-876d8e1bb696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "torch.randn(1,1,3,1) / x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.6518,  0.0931,  0.2568],\n",
              "          [ 0.7315, -0.1045, -0.2882],\n",
              "          [ 0.9381, -0.1340, -0.3696]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajMHwqwLoXTx",
        "colab_type": "text"
      },
      "source": [
        "In addition to the \"+\" operator, broadcasting can be applied for the other arithmetic operations of subtraction, multiplication, and division.\n",
        "\n",
        "\n",
        "While broadcasting is PyTorch's way of autmatically reshaping a tensor so that arithmetic operations can proceed unhitched, we sometimes want to explicity reshape a tensor to a specific shape. In PyTorch the `view()` method in `torch.Tensor` allows us to do exactly just that. Below we will reshape the `z` tensor to have 3 rows and 2 columns instead of 2 rows and 3 columns (ie, we perform a \"transpose\" operation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMAGvHvTi1-K",
        "colab_type": "code",
        "outputId": "d92e5361-302a-4d93-d9a3-0be1638a942f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "z.view(3,2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7686, -1.0158],\n",
              "        [-3.0055, -0.7388],\n",
              "        [ 0.9558, -0.6715]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDJRD3aMuOyg",
        "colab_type": "text"
      },
      "source": [
        "We can also introduce dummy singlton dimensons using the `view()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BtsocdpuOSK",
        "colab_type": "code",
        "outputId": "d5013bae-b9ae-4263-9384-2e550bf99e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "z.view(1,3,2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7686, -1.0158],\n",
              "         [-3.0055, -0.7388],\n",
              "         [ 0.9558, -0.6715]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqehPMGxuX89",
        "colab_type": "text"
      },
      "source": [
        "While the number of elements is still the same, we have introduced a singlton in the first dimension that is just 1. \n",
        "\n",
        "We can also use \"-1\" as a way to specify anything that is left over after a reshape.  For example, below says reshape `z` to have 3 rows, and then let it have as many columns left over in the data (just 3 in our case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBX1QRi7uXZB",
        "colab_type": "code",
        "outputId": "ecae5fa2-5847-4c99-8a8b-5ba72ae748d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "z.view(3,-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7686, -1.0158],\n",
              "        [-3.0055, -0.7388],\n",
              "        [ 0.9558, -0.6715]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl81kcrgux0Q",
        "colab_type": "text"
      },
      "source": [
        "Using such operation with the `view()`  method in PyTorch are very common. \n",
        "\n",
        "\n",
        "# CPU and GPU devices\n",
        "\n",
        "One of the significant advantages of using PyTorch tensors as opposed to Numpy arrays is the ability to utilize the GPU to offload computations. By default when we create tensors in PyTorch, the tensors are computed with the CPU. If we want to use the GPU, we have to specify which GPU device we want to use and offload the PyTorch tensor on the GPU device.\n",
        "\n",
        "To see if a GPU device is available on your system, you can use the function `torch.cuda.is_available()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zjZ9IbHwdFU",
        "colab_type": "code",
        "outputId": "e33f5c79-979a-4c23-9d2a-f901d8f5527a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMCe1NPRwpUQ",
        "colab_type": "text"
      },
      "source": [
        "If the output of this method is True, congratulations! PyTorch has access to a GPU that you can use to greatly speed up computations! If the output is False and you do have a GPU, then you need to recheck the installation of PyTorch with the CUDA and cuDNN device drivers. \n",
        "\n",
        "It is very common to define the device that you have with the `torch.device()` method. For example, if you have CUDA properly installed and the output of `torch.cuda.is_available()` is True, then you can have a variable called `device` that specifies which device you are using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHceCOaqxKJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn4h7Z8nxh0t",
        "colab_type": "text"
      },
      "source": [
        "Even if you have GPU but prefer to use CPU, then you can similarly specify to use CPU by running:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfi2WD98xLF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDVsKk1OxuWL",
        "colab_type": "text"
      },
      "source": [
        "Finally, if you want your code to flexibily run on either CPU or GPU, then you can have a Python conditional statement such as the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JmmX8ofuB7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "511QPaxlZGqh",
        "colab_type": "text"
      },
      "source": [
        "This conditional will automatically then set device to either CPU or GPU depending on what you have. It is very common to see deep learning examples to use such device specifications at the begining of the code. \n",
        "\n",
        "Once you have setup  the device, you can simply send the tensors you have created to it. This can be done with the `to()` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PffJVtZkZJjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_on_specified_device = z.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QJD77qWx3AK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Importing other packages for use with PyTorch\n",
        "\n",
        "While PyTorch is a powerful deep leanrning framework, there are many other libraries in Python that we will need to prepare data and aid us in building PyTorch applications. In particular, NumPy (which we have been discussing), Pandas, Scikit-Learn, and Matplotlib are essential general data tools that we will need. If you have installed the Python distribution from Anaconda, these libraries are already included. Otherwise, you should install them using either `pip` or `conda`\n",
        "\n",
        "It is very common for us to want to convert a NumPy Array to a PyTorch tensor. Lets revisit our PyTorch tensor `z`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsMUveTTyC1u",
        "colab_type": "code",
        "outputId": "9961d369-f858-491e-8804-39c1c11a200c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7686, -1.0158, -3.0055],\n",
            "        [-0.7388,  0.9558, -0.6715]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVsWKkkXeEff",
        "colab_type": "text"
      },
      "source": [
        "Clearly from the printout we can see that `z` is a PyTorch tensor as we exepct. Let's say we would like to plot the first row of `z`. We can specify the first row of `z` using indexing the slize `z[0,:]`. Matplotlib gives us powerful plotting tools, so lets use that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HQ79JSMedmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt;\n",
        "\n",
        "## This results in an error! Matplotlib does not recognize PyTorch tensors!\n",
        "# plt.plot(z[0,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKu7TOXnf72O",
        "colab_type": "text"
      },
      "source": [
        "If you run the above you will get an error! This is because Matplotlib at the time of this writing does not recognize PyTorch tensors. We will have to convert this PyTorch tensor to a NumPy Array. \n",
        "\n",
        "All PyTorch tensors have the method `numpy()` that convert the PyTorch tensor to a Numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEfvXM1ef7Mp",
        "colab_type": "code",
        "outputId": "e665e02e-4478-471a-8d29-acdf82e307a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "first_row = z[0,:].numpy()\n",
        "type(first_row)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2NotpBngrp4",
        "colab_type": "text"
      },
      "source": [
        "Now we can either plot `first_row` or just directly convert the PyTorch tensor to NumPy Array and plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7iwVKsxgrJK",
        "colab_type": "code",
        "outputId": "eed0d421-9bb5-445f-81cb-4beef4bdee40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "plt.plot(z[0,:].numpy());"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwSUVxgghQqc",
        "colab_type": "text"
      },
      "source": [
        "We can similarly convert a NumPy Array to a PyTorch tensor using the function `torch.tensor()`. Earlier we showed how `torch.tensor()` accepts a Python list, but it also supports taking as inputs NumPy Arrays and even PyTorch tensors (more on that later). Let's create a NumPy Array of 3 elements all having the value of 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siHSTyCqhzg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "const_arr_numpy = 5*np.ones(3)\n",
        "\n",
        "const_arr_tensor = torch.tensor(const_arr_numpy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MqNOAKbekKW",
        "colab_type": "text"
      },
      "source": [
        "`const_arr_tensor` is now a PyTorch tensor that we can apply the usual PyTorch operations on. \n",
        "\n",
        "There has been something that we have not discussed yet though and it will be a headache when passing data between PyTorch tensors and NumPy Arrays if not careful: data types. By default, when we create a NumPy Array the datatype is a 64-point float. We can check this with the `dtype` attribute of NumPy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXJUhItih_y4",
        "colab_type": "code",
        "outputId": "06526ed0-df4f-4930-d7a8-00720699b8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "const_arr_numpy.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7892PvbifQV6",
        "colab_type": "text"
      },
      "source": [
        "When we convert this NumPy Array to a PyTorch tensor, `torch.tensor()` is smart enough to infer the data and casts the converted PyTorch tensor to be of the same type. We can similarly check the data type of our newly created array with the `dtype` attribute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWa_M870iQuv",
        "colab_type": "code",
        "outputId": "0ffe65e0-13f0-466a-da11-22384cb28028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "const_arr_tensor.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAJyphWKi3SQ",
        "colab_type": "text"
      },
      "source": [
        "As expected we see that the tensor's data type is a 64-point float just like the NumPy array that was passed to `torch.tensor()` in the assignment. \n",
        "\n",
        "This is all well and good until you try to mix this tensor with other tensors you have created with PyTorch. This is because the default datatype in PyTorch tensors are 32-point tensors. Let's check the tensor `z` datatype that we had created before:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXYBLG3dibpr",
        "colab_type": "code",
        "outputId": "61e74930-d7e8-479e-ad6b-34ba2af5d8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNFTe70nlIdC",
        "colab_type": "text"
      },
      "source": [
        "Recall that we created `z` using `torch.randn()` and since 32-point floats are PyTorch's default, we see that indeed this is the case with `z`. \n",
        "\n",
        "When we try to add `z` to `const_arr_tensor` (with broadcasting) we get an error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyPuikrX10AL",
        "colab_type": "code",
        "outputId": "58a7f1df-b852-40ec-81bb-308c347403b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "const_arr_tensor.float()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 5., 5.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD0VtzWtYwfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## results in data type error\n",
        "# z + const_arr_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0dFGSRR1hK5",
        "colab_type": "text"
      },
      "source": [
        "We can avoid this error by type casting either `z` or `const_arr_tensor` - let's type cast to a 32-point float "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1ekc0rnZ6ir",
        "colab_type": "code",
        "outputId": "9cb5efc6-2ab1-42cf-a540-0edcdabc96ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "z + const_arr_tensor.float()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.7686, 3.9842, 1.9945],\n",
              "        [4.2612, 5.9558, 4.3285]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyzAHiyk4GvU",
        "colab_type": "text"
      },
      "source": [
        "Alternative, when we converted the NumPy Array to the PyTorch tensor using `torch.tensor()` we could have made the data type explicit by specifying the dtype argument. This would look as follows: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGn6l1cQ2Rfm",
        "colab_type": "code",
        "outputId": "aab2e647-b0f4-4194-a41e-f0be481e33b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "const_arr_tensor = torch.tensor(const_arr_numpy, dtype = torch.float32)\n",
        "\n",
        "z + const_arr_tensor # no error!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.7686, 3.9842, 1.9945],\n",
              "        [4.2612, 5.9558, 4.3285]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fnyP1DU4nV3",
        "colab_type": "text"
      },
      "source": [
        "Now that we have setup the tensors with the datatype that we want, lets take a step back at the variables that we have active in memory. The NumPy array `const_arr_numpy` and the PyTorch tensor `const_arr_tensor` have the same values but occupy two different places in memory. So even though they store the same values, they are two different variables and affecting one will not affect the other. In other words, `const_arr_tensor`is a copy of `const_arr_numpy` by *value* as opposed to a *copy by reference*.\n",
        "\n",
        "\n",
        "\n",
        "Sometimes we wish to *copy by reference* however. We can perform a copy by reference by using the function `torch.from_numpy()`. Let's illustrate with an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXso1FWx7J0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "const_arr_tensor = torch.from_numpy(const_arr_numpy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH9jGzv073Wm",
        "colab_type": "text"
      },
      "source": [
        "Although `const_arr_tensor`is a PyTorch tensor and `const_arr_numpy` is a NumPy Array, they both share the same memory! So changing the values in one of them will change the other. For example, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLKMKnc38toX",
        "colab_type": "code",
        "outputId": "19b45af8-a731-4675-adc1-1c65a137c0e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "const_arr_tensor += 1\n",
        "print(const_arr_tensor)\n",
        "print(const_arr_numpy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([6., 6., 6.], dtype=torch.float64)\n",
            "[6. 6. 6.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I74J25C98s-x",
        "colab_type": "text"
      },
      "source": [
        "Note that as in NumPy, the `+=` is an in-place operation that directly manipulates `const_arr_tensor` (and `const_arr_numpy` in this case) without creating any new objects (as opposed to an assignment such as `const_arr_tensor = 1 + const_arr_tensor`). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gPKfF33cYdS",
        "colab_type": "text"
      },
      "source": [
        "# Reading data from a file\n",
        "\n",
        "\n",
        "It is no secret that machine learning algorithms are hungry for data. To build machine learning applications, we will need to load data into PyTorch. In addition to Python's own file reading and writing management,  NumPy and Pandas offer many convenient functions for us to load external datasets into a structued array. We can then use the NumPy converter methods we discussed in the previous section to convert the loaded datasets into PyTorch tensors. \n",
        "\n",
        "\n",
        "Let's consider an example of reading a CSV file with Pandas. We will load the Iris data set hoseted in this GitHub Gist: https://gist.github.com/curran/a08a1080b88344b0c8a7\n",
        "\n",
        "This is the Gist website that contains the CSV file. To get the raw CSV file we would have to use the direct URL to the CSV that you can get from the \"Raw\" button in GitHub Gist: https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/d546eaee765268bf2f487608c537c05e22e4b221/iris.csv\n",
        "\n",
        "\n",
        "As of Pandas version `0.19.2` and later, we can read a CSV file from a URL directly into a Pandas DataFrame using the  `read_csv()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y3n57dsGzp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/d546eaee765268bf2f487608c537c05e22e4b221/iris.csv\"\n",
        "\n",
        "df = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bcTCEUgihWd",
        "colab_type": "code",
        "outputId": "eac134ad-da6d-4fbc-9623-7067ecb5f9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLDzvBivWZnh",
        "colab_type": "text"
      },
      "source": [
        "The Iris dataset is a famous dataset promoted by the early 20th century statistician Ronald Fischer where he used it to illustrate the Linear Discriminant Analysis algorithm (which today you can simply run from Scikit-learn). Today the Iris dataset is still used as an example data set to test out algorithmic ideas against a real world dataset that is not too large for quick iteration. \n",
        "\n",
        "From Wikipedia, \n",
        "\n",
        "> The [Iris] data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other.\n",
        "\n",
        "\n",
        "\n",
        "We can see in the data set that we loaded the first four columns are the flower features and the last column is the type of flower (`species`). In machine learning, the last column is usually the \"target\" variable we are interested in predicting from the features. We often represent the set of features (`sepal_length`,\t`sepal_width`,\t`petal_length`,\t`petal_width`) as their own own array and the targets, `species`, as a separate array. \n",
        "\n",
        "We will call the features array `X` and the targets `y`. One way to get the set of features in the Pandas DataFrame is to specify the column names as a list of the feature names. Alternatively, since our data set is so clean, we can just select the first 4 columns with the `iloc` method. We can then use the `.values` attribute to just get the underlying NumPy array in the DataFrame:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jztZtb0ZE2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:,:3].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FprPoWrYciXI",
        "colab_type": "text"
      },
      "source": [
        "In our case since the DataFrame is so clean, we have no missing values and `X` is a purely numeric array. Often though real data may be messy and contain non-numeric values. You will have to take extra steps to prepare the data to ensure you have a purely numeric array. Often using the combination of the methods `pd.to_numeric()` from Pandas and `np.isnan()` from NumPy helps to convert the array to numeric and identiy where missing (NaN or \"Not a Number\" values) occur which you can then decide how to impute. \n",
        "\n",
        "Here since our data is so clean, before converting it to a PyTorch tensor we'll just check its data type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwpgKuUGZgr7",
        "colab_type": "code",
        "outputId": "599f9153-ccf0-4698-b4a0-911b2b23a808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc5nX-vvenlu",
        "colab_type": "text"
      },
      "source": [
        "As discussed earlier, PyTorch tensors by default are 32-bit floating points so when we convert this array we will specify the data type. If we have specified our device (GPU or CPU) with the `device` variable as we have done previously, we can also place the tensor on the device all in one line:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBC7ZLsSceUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tensor = torch.tensor(X, dtype = torch.float32).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDeehFXcfOsT",
        "colab_type": "text"
      },
      "source": [
        "Now that we have prepared the features in `X_tensor` for use in PyTorch, we need to prepare the targets in the `species` column. The `species` column is a list of strings specifying the species of the flower. In machine learning applications, we often want to encode such lists as a numerical vector. \n",
        "\n",
        "Let's first print out the unique list of species classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSmGgl4Me-Db",
        "colab_type": "code",
        "outputId": "8b2b3b20-2da4-49f7-8fd8-2cc287660a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pd.unique(df.species)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KOgcU7igaHw",
        "colab_type": "text"
      },
      "source": [
        "We see that there are 3 total classes: 'setosa', 'versicolor', and 'virginica.'\n",
        "\n",
        "While we can manually iterate through each row in `df.species` and assign a numeric label to each of these 3 classes,  we recommend using the suite of label preparation utitlities provided by the Scikit-learn library. `LabelEncoder` in particular is useful for us to assigning a unique label integer to each of the classes. Below is an example on how to use it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_zE3jgwgXfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5bYto0lhASS",
        "colab_type": "code",
        "outputId": "495f1f38-6c4f-4cf3-bdf3-d84de3836dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_encoder = LabelEncoder()\n",
        "target_encoder.fit(df.species)\n",
        "\n",
        "y = target_encoder.transform(df.species)\n",
        "\n",
        "np.unique(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR1ifdcAhvK4",
        "colab_type": "text"
      },
      "source": [
        "Now the NumPy array `y` has a numeric value associated with each of our three classes. If we want to know which integer ID corresponds to what label, we can simply use the `inverse_transform()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4I535zGhHk4",
        "colab_type": "code",
        "outputId": "d806d912-1045-4f0e-f3d4-a592b9f86cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_encoder.inverse_transform(np.unique(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOYx0b0BiCuG",
        "colab_type": "text"
      },
      "source": [
        "Now that `y` is a numeric NumPy array we can transform it to a PyTorch tensor with the `torch.tensor` methods we showed before. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc48HzDsuy-Q",
        "colab_type": "text"
      },
      "source": [
        "# GPU device management \n",
        "\n",
        "If you have multiple GPUs,  by default `torch.device(\"cuda\")` specifies the first GPU (GPU 0 as PyTorch GPU indexing starts from 0). You can alternatively specifiy which GPU you want to use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMBLk4u4hUfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda0 = torch.device('cuda:0')\n",
        "cuda1 = torch.device('cuda:1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL4vHA0MzGUO",
        "colab_type": "text"
      },
      "source": [
        "Now you can use either `cuda0` or `cuda1` to specify where you want a tensor to be. For example, below `x_device_0` is on GPU 0 and `x_device_1` is on GPU  1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAYNf_zHj-eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_device_0 = torch.randn(3,4).to(cuda0)\n",
        "#x_device_1 = torch.randn(3,4).to(cuda1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n66QTFe1zzq3",
        "colab_type": "text"
      },
      "source": [
        "Alternatively, you can use Python's `with` contex manager to speciy which device to use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVyiHS8NmLNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.cuda.device(0):\n",
        "    # allocates a tensor on GPU 1\n",
        "    x_device_0 = torch.randn(3,4).cuda() # on device 0\n",
        "    \n",
        "    a = torch.randn(3,4).to(device) # also on device 0\n",
        "\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2R9ECJ909zc",
        "colab_type": "text"
      },
      "source": [
        "You can use the `device` attribute to see which device a tensor is on:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9EyFqyimMha",
        "colab_type": "code",
        "outputId": "95a19c22-6cbb-4b24-9dcc-07c6d6bb6b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_device_0.device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMHyRj791V7X",
        "colab_type": "text"
      },
      "source": [
        "PyTorch also gives you wrappers to monitor how much memory is used by your different devices with the functions `torch.cuda.memory_allocated()`, `torch.cuda.max_memory_allocated()`,  `torch.cuda.memory_cached()`, and `torch.cuda.max_memory_cached()` as their names imply. For example, to see the maximum memory allocated on your device, just run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iijYtOCZ1m26",
        "colab_type": "code",
        "outputId": "24f1523d-e5cd-4341-8ded-22c2515ddbd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.max_memory_allocated(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}